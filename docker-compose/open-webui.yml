services:
  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    restart: unless-stopped
    ports:
      - "${CHAT_PORT}"
    deploy:
      resources:
        limits:
          memory: ${CHAT_MEMORY_LIMIT}
    environment:
      - OLLAMA_BASE_URL=http://host.docker.internal:${OLLAMA_PORT}
      - WEBUI_SECRET_KEY=${OPENWEBUI_SECRET_KEY}
      - DATA_DIR=/app/backend/data
      - ENABLE_SIGNUP=true
      - DEFAULT_USER_ROLE=admin
      - ENABLE_MODEL_FILTER=false
      - ENABLE_OLLAMA_API=true
      - OLLAMA_BASE_URLS=http://host.docker.internal:${OLLAMA_PORT}
    volumes:
      - ../data/open-webui:/app/backend/data
      - ../shared:/app/shared
    networks:
      - traefik_network:
          external: true
    extra_hosts:
      - "host.docker.internal:host-gateway"
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.open-webui.rule=Host(`${CHAT_SUBDOMAIN}.${DOMAIN}`)"
      - "traefik.http.routers.open-webui.entrypoints=websecure"
      - "traefik.http.routers.open-webui.tls=true"
      - "traefik.http.services.open-webui.loadbalancer.server.port=${CHAT_CONTAINER_PORT}"